**Q: What is linear regression?**

A: Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. It assumes a linear relationship between the variables and estimates the coefficients of the linear equation that best fits the data.

**Q: What are the assumptions of linear regression?**

A: The assumptions of linear regression include linearity, homoscedasticity, independence of errors, normality of errors, and absence of multicollinearity.

**Q: What is the difference between simple linear regression and multiple linear regression?**

A: Simple linear regression has only one independent variable, while multiple linear regression has two or more independent variables.

**Q: How do you measure the performance of a linear regression model?**

A: The performance of a linear regression model can be measured using metrics such as mean squared error, R-squared, and adjusted R-squared.

**Q: What is the purpose of the intercept term in linear regression?**

A: The intercept term in linear regression represents the value of the dependent variable when all independent variables are equal to zero. It helps to account for variations in the data that cannot be explained by the independent variables.

**Q: How do you handle multicollinearity in linear regression?**

A: Multicollinearity occurs when two or more independent variables are highly correlated. It can be handled by removing one of the correlated variables, transforming the variables, or using regularization techniques such as ridge regression.

**Q: What is overfitting in linear regression?**

A: Overfitting occurs when a model is too complex and fits the noise in the data, rather than the underlying patterns. It can be addressed by using regularization techniques or by simplifying the model.

**Q: Can you use linear regression for classification?**

A: No, linear regression is a method for regression, not classification. For classification, other methods such as logistic regression or support vector machines should be used.

**Q: What is the significance of the p-value in linear regression?**

A: The p-value measures the probability that the observed relationship between the dependent and independent variables occurred by chance. A p-value less than the significance level (usually 0.05) indicates that the relationship is statistically significant.

**Q: What is the difference between the slope and the coefficient in linear regression?**

A: The slope is the change in the dependent variable for a one-unit change in the independent variable. The coefficient is the estimated value of the slope in the linear regression equation.

**Q: What is the role of the residual in linear regression?**

A: The residual is the difference between the observed value of the dependent variable and the predicted value from the linear regression equation. It is used to assess the goodness of fit of the model and to check for violations of the assumptions.

**Q: How do you handle missing values in linear regression?**

A: Missing values can be handled by removing the observations with missing values, imputing the missing values, or using techniques such as multiple imputation.

**Q: What is the difference between correlation and linear regression?**

A: Correlation measures the strength of the relationship between two variables, while linear regression models the relationship between the dependent and independent variables and estimates the coefficients of the linear equation that best fits the data.

**Q: How do you determine the appropriate number of independent variables in a linear regression model?**

A: The appropriate number of independent variables in a linear regression model can be determined using techniques such as stepwise regression, forward selection, or backward elimination. It is important to balance the trade-off between model complexity and model accuracy.

**Q: What is the purpose of regularization in linear regression?**

A: Regularization is used in linear regression to prevent overfitting by adding a penalty term to the objective function. Regularization techniques such as ridge regression and lasso regression help to shrink the coefficients and simplify the model.

**Q: Can you explain the difference between a residual plot and a Q-Q plot in linear regression?**

A: A residual plot is a plot of the residuals versus the fitted values and is used to check for violations of the assumptions of linearity and homoscedasticity. A Q-Q plot is a plot of the residuals versus the quantiles of a theoretical normal distribution and is used to check for normality of the errors.
